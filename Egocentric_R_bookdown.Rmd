--- 
title: "Egocentric network analysis with R"
author: "[Raffaele Vacca](http://www.raffaelevacca.com/)"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
bibliography: [book.bib, packages.bib]
csl: apa.csl
link-citations: yes
description: "Personal network analysis with R"
---

# Introduction

This book is a companion to [my workshop](http://www.raffaelevacca.com/teaching/egocentric-r/) on egocentric network analysis with R. Over the past several years I have taught this workshop at different conferences and summer schools on social network analysis, personal networks, and network science -- such as [INSNA Sunbelt](https://www.insna.org/) conferences, [NetSci](https://netscisociety.net/home) conferences, and the [UAB Barcelona Course on Personal Network Analysis](https://sway.office.com/1TpXMhGqKa7fTsAC). The book is a work in progress and I'll keep updating it as I continue to teach the workshop and related courses.

A Spanish translation of part of this book has appeared in the journal [REDES - Revista hispana para el anÃ¡lisis de redes sociales](https://revistes.uab.cat/redes/article/view/v31-n2-vacca). My colleagues and I provide a more in-depth discussion of personal network analysis and the methods covered in this workshop in our textbook on personal network research [@mccarty_conducting_2019]. See the bibliography at the end of the book for a list of other useful references on egocentric or personal network analysis.

Feel free to [contact me](http://www.raffaelevacca.com/) to know more about this workshop and how to take it, or to give me feedback or report any issue about this book.

[![Conducting personal network research](./Figures/McCarty_et_al_2019_cover.jpg){width=50%}](https://www.guilford.com/books/Conducting-Personal-Network-Research/McCarty-Lubbers-Vacca-Molina/9781462538386/authors)

## Workshop setup {#setup}

To take this workshop you need to:

1. Download the latest version of **R** [here](https://cran.r-project.org/mirrors.html) (select a location near you)
    * Follow instructions to install R in your computer
    * If you downloaded R some time ago, please update it to the latest version
2. Download the latest version of **RStudio** (free version) [here](https://posit.co/download/rstudio-desktop/)
    * Follow instructions to install RStudio in your computer
    * If you downloaded RStudio some time ago, please update it to the latest version
3. Install the **R packages** listed [below](#packages)
    * Open RStudio and go to `Top menu > Tools > Install packages...`
    * Install each package in the list
4. Bring your **laptop** to the workshop
5. Download the **workshop folder** and save it to your computer: see [below](#materials) 
    * I recommend that you do this in class at the beginning of the workshop so as to download the most updated version of the folder.
6. Once in class, go to the workshop folder on your computer (point 5 above) and double-click on the _R project_ file in it (`.Rproj` extension). 
    * That will open RStudio: you're all set!

**NOTE:** It's very important that you save the workshop folder _as downloaded_ to a location in your computer, and open the `.Rproj` _within that folder_. By doing so, you will be opening RStudio _and_ setting the workshop folder as your [R working directory](#starting-R-and-loading-packages). All our R scripts assume that working directory. In particular, they assume that the `Data` subfolder is in your R working directory. You can type `getwd()` in your R console to see the path to your R working directory and make sure that it's correctly pointed to the location of the workshop folder in your computer. 

## Workshop materials {#materials}
The materials for this workshop consist of this book and the workshop folder. 

You can **download the workshop folder** from [this GitHub repository](https://github.com/raffaelevacca/egocentric-r-book): 

1. Click on the `Code` green button > Download ZIP
2. Unzip the folder and save it to your computer

The workshop folder contains several files and folders, but you only need to focus on the following: 

* `Scripts` subfolder: all the R code shown in this book. 
* `Data` subfolder: all the data we're going to use.
* `egocentric-r.Rproj`: the workshop's R project file (you use this to launch RStudio).

The `Scripts` subfolder includes different R script (.R) files. You can access and run the R code in each script by opening the corresponding .R file in RStudio. Each script in `Scripts` corresponds to one of the following chapters (see the table of contents):

2. [Basics of the R language](#basics) (`02_Basics` script and slideshow).
3. [Representing and visualizing ego-networks in R](#represent) (`03_Representing_egonets.R` script and slideshow).
4. [Analyzing ego-network composition](#composition) (`04_Composition` script and slideshow).
5. [Analyzing ego-network structure](#structure) (`05_Structure` script and slideshow).
6. [Modeling tie- or alter-level variables with multilevel models](#multilevel) (`06_Multilevel` script and slideshow).
7. [Introduction to the `egor` package](#egor) (`07_egor` script and slideshow).
8. [Supplementary topics](#supplementary) (`08_Supplementary` script and slideshow). 

The **slides** used for this workshop can be downloaded [here](https://www.dropbox.com/sh/o8rncfrtks1sx3s/AACyzgkwbhTDWsPIKST_2e6Ya?dl=0).

## R settings

### Required R packages {#packages}

* For descriptive statistics:
    - [`janitor`](https://cran.r-project.org/web/packages/janitor/vignettes/janitor.html)
    - [`skimr`](https://cran.r-project.org/web/packages/skimr/vignettes/skimr.html)
* For network data, measures, visualization:
    - [`egor`](https://github.com/tilltnet/egor)
    - [`ggraph`](https://github.com/thomasp85/ggraph)
    - [`igraph`](https://igraph.org/)
    - [`intergraph`](https://mbojan.github.io/intergraph/)
    - [`statnet`](http://statnet.org/)
    - [`tidygraph`](https://github.com/thomasp85/tidygraph)
* To fit multilevel statistical models and view their results:
    - [`broom.mixed`](https://cran.r-project.org/web/packages/broom.mixed/vignettes/broom_mixed_intro.html)
    - [`car`](https://cran.r-project.org/web/packages/car/index.html)
    - [`ggeffects`](https://strengejacke.github.io/ggeffects/)
    - [`lme4`](https://github.com/lme4/lme4)
* General:
    - [`tidyverse`](https://www.tidyverse.org/). This is a collection of different packages that share a common language and set of principles, including `dplyr`, `ggplot2`, and `purrr`. See [Wickham and Grolemund (2017)](http://r4ds.had.co.nz/) for more information.

### RStudio options

RStudio gives you the ability to select and change various settings and features of its interface: see the `Preferences...` menu option. These are some of the settings you should pay attention to:

* `Preferences... > Code > Editing > Soft-wrap R source file`. Here you can decide whether or not to wrap long code lines in the editor. When code lines in a script are _not_ wrapped, be aware that some code will be hidden if script lines are longer than your editor window's width (you'll have to scroll right to see the rest of the code). With a script (`.R`) file open in the editor, try both options (checked and unchecked) to see what you're more comfortable with.
* `Preferences... > Code > Display > Highlight R function calls`. This allows you to highlight all pieces of code that call an R function ("command"). I find function highlights very helpful to navigate a script and suggest that you check this option.

## Data

This workshop uses real-world data collected in 2012 with a personal network survey among 107 Sri Lankan immigrants in Milan, Italy. Out of the 107 respondents, 102 reported their personal network. All data are in the `Data` subfolder. 

The data files include ego-level data (gender, age, educational level, etc. for each Sri Lankan respondent), alter attributes (alter's nationality, country of residence, closeness to ego etc.), and information on alter-alter ties. Each personal network has a fixed size of 45 alters. Information about data variables and categories is available in `./Data/codebook.xlsx`.

All data objects are saved as R objects in the R data file `data.rda`. Data objects are the following: 

+ `ego.df`: A data frame with ego-level attributes for all respondents (egos).
+ `alter.attr.all`: A data frame with alter-level attributes for all alters from all respondents.
+ `gr.list`: A list. Each list element is one ego-network stored as an `igraph` object.
+ `alter.attr.28`: A data frame with alter-level attributes only for alters nominated by ego ID 28.
+ `gr.28`: The ego-network of ego ID 28 stored as an `igraph` object.
+ `gr.ego.28`: The same as `gr.28`, but with the node of the ego included in the `igraph` object.

The R data objects above were imported from raw csv data files. All csv files are in the `./Data/raw_data/` subfolder:

+ `ego_data.csv`: A csv file with ego-level data for all the egos.
+ `alter_attributes.csv`: A single csv file including attributes of all alters from all egos.
+ `alter_ties_028.csv`: The edge list for ego ID 28's egocentric network.
+ `alter_attributes_028.csv`: The alter attributes in ego ID 28's egocentric network.
+ `adj_028.csv`: The adjacency matrix for ego ID 28's egocentric network.
+ `alter_ties.csv`: A single csv file with the edge list for all alters from all egos.

For most of the workshop we will directly use R data objects in `data.rda`. We will _not_ focus on importing ego-network data from outside sources (for example, csv files). However, Section \@ref(egor-import) shows you how the data objects in `data.rda` were created by importing csv files with the `egor` package. Section \@ref(import-igraph) covers importing ego-network data using just `tidyverse` and `igraph`.

## Author and contacts

I'm an assistant professor of sociology at the [University of Milan](https://www.unimi.it/en) in the [Deparment of Social and Political Sciences](http://eng.sps.unimi.it/ecm/home) and its [Behave Lab](https://behavelab.org/). My main research and teaching interests are social networks, migration, health inequalities, and studies of science. I also teach and do research on data science, statistics, and computational methods for the social sciences. More information about me, my work and my contact details is [here](http://www.raffaelevacca.com/). 

```{r include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown'
), 'packages.bib')
```

<!--chapter:end:index.Rmd-->

# R basics {#basics}

```{r include=FALSE, cache=FALSE}
knitr::read_chunk("./Scripts/02_Basics.R")
```

## Overview

This chapter covers some basic tools and characteristics of the R language that we'll use in the workshop. While this obviously can't be a comprehensive introduction to R, we'll demonstrate some essential R notions and features that are commonly used in social science data analysis, including (egocentric) social network analysis. 

The script covers the following topics:

* Starting R, getting help with R.
* Creating and saving R objects.
* Vectors and matrices, data frames and tibbles.
* Arithmetic and relational operations.
* Subsetting vectors, matrices, and data frames.

## Starting R and loading packages {#starting-R-and-loading-packages}

+ Before starting any work in R, you normally want to do two things:
    * Make sure your R session is pointing to the correct _working directory_.
    * Install and/or load the _packages_ you are going to use. 
+ **Working directory**. By default, R will look for files and save new files in this directory. 
    * Type `getwd()` in the console to view your current working directory.
    * If you opened RStudio by double-clicking on a project (`.Rproj`) file, then the working directory is the folder where that file is located. 
    * You can always use `setwd()` to manually change your working directory to any path, but it's usually more convenient to work with R projects and their default working directory instead.
    * In RStudio, you can also check the current working directory by clicking on the `Files` panel.
+ **R packages**. There are two steps to using a package in R:
    1. **Install** the package. _You do this just once_. Use `install.packages("package_name")` or the appropriate RStudio menu (`Tools > Install Packages...`). Once you install a package, the package files are in your system R folder and R will be able to always find the package there.
    2. **Load** the package in your current session. Use `library(package_name)` (_no_ quotation marks around the package name). _You do this in each R session in which you need the package_, that is, every time you start R and you need the package. 
+ An R package is just a collection of **functions**. You can only use an R function if that function is included in a package you loaded in the current session.
+ Sometimes two different functions from two different packages have the same **name**. For example, both the `igraph` package and the `sna` package have a function called `degree`. If both packages are loaded, typing just `degree` might give you unexpected results, because R will pick one of the two functions (the one in the package that was loaded most recently), which might not be the function you meant. 
    * To avoid this problem, you can use the `package::function()` notation: `igraph::degree()` will always call the `degree` function from the `igraph` package, while `sna::degree()` will call the `degree` function from the `sna` package. 
+ Tip: To check the package that a function comes from, just go to that function's manual page. The package will be indicated in the first line of the page. E.g., type `?degree` to see where the `degree` function comes from. 
    * If no currently loaded package has a function called `degree`, then typing `?degree` will cause a warning (`No documentation for 'degree'`).
    * If multiple, currently loaded packages have a function called `degree`, then typing `?degree` will bring up a page with the list of all those packages.
+ This workshop will use a number of packages, listed [here](#packages).

### Console vs scripts

+ When you open RStudio, you typically see two separate windows: the script editor and the console. You can write R code in either of them.
+ **Console**. Here you write R code line by line. Once you type a line, you press `ENTER` to execute it. By pressing `ARROW UP` you go back to the last line you ran. By continuing to press `ARROW UP`, you can navigate through all the lines of code you previously executed. This is called the "commands history" (all the lines of code executed in the current session). You will lose all this code (all the history) when you quit R, unless you explicitly save the history to a file (which is not what you typically do, you should just write the code in a script).  
+ **Script editor**. Here you write a script. This is the most common way of working with R. A script is simply a plain text file where all your R code is saved. If your work is in a script, it is **reproducible**.
+ Both the R standard GUI and RStudio have a script editor with several helpful tools. Among other things, these allow you to run a script while you write it. By pressing `CTRL+ENTER` (Windows) or `CMD+ENTER` (Mac), you run the script line your cursor is on (or the selected script region). 
    * Note that with RStudio you can run the single script line where your cursor is; a whole highlighted region of code; the region of code from the beginning of the script up to the line where your cursor is; the region of code from the line where your cursor is up to the end of the script. See the *Code* menu and its keyboard shortcuts.
+ The script editor also allows you to save your script. In RStudio, see `File > Save` and its keyboard shortcut. R script files commonly have a `.R` extension (e.g. "`myscript.R`"). But note that a script file is just a text file (like any `.txt` file), which you can open and edit in any text editor, or in Microsoft Word and the likes.
+ You can also run a whole script altogether --- this is called **sourcing** a script. By running `source("myscript.R")`, you source the script file `myscript.R` (assuming the file is in your working directory, otherwise you'll have to enter the whole file path). In RStudio: see *Code* > *Source* and its keyboard shortcut.
+ In both the console and the script editor, any line that starts by `#` is called a **comment**. R disregards comments --- it just prints them as they are in the console (does not parse and execute them as programming code). Remember to always use comments to document what your code is doing (this is good for yourself and for others).
+ In RStudio you can navigate the script headings in your script with a drop-down menu in the bottom-left of the script editor. Any line that starts by `#` and ends by `####`, `----`, or `====` is read as a heading by RStudio.

### Getting help

+ Getting help is one of the most common things you do when using R. As a beginner, you'll constantly need to get help (for example, read manual pages) about R functions. Also as an experienced user, you'll often need to go back to the manual pages of particular functions or other R help resources. At any experience level, using R involves constantly using its documentation and help resources. 
+ The following are a few help tools in R:
    * `help(...)` or `?...` are the most common ways of getting help: they send you to the R manual page for a specific function. E.g. `help(sum)` or `?sum` (they are equivalent).
    * `help.start()` (or RStudio: `Help > R Help`) gives you general help pages in html (introduction to R, references to all functions in all installed packages, etc.).
    * `demo()` gives you demos on specific topics. Run `demo()` to see all available topics.
    * `example()` gives you example code on specific functions, e.g. `example(sum)` for the function `sum`.  
    * `help.search(...)` or `??...` search for a specific string in the manual pages, e.g. `??histogram`.
+ In addition to built-in help facilities within R, there are plenty of ways to get **R help online**. Certain popular R packages have their own website, e.g. [ggplot2](http://ggplot2.tidyverse.org/), [igraph](http://igraph.org/), and [statnet](http://www.statnet.org/). Other websites for general R help include [rdocumentation.org](http://www.rdocumentation.org/) and [stackoverflow.com](http://stackoverflow.com/). See the workshop slides or talk to me for more information.

```{r starting, include=TRUE, cache=FALSE, tidy= FALSE, message=FALSE}
```

```{r include=FALSE, cache=FALSE}
rm(list=ls())
```

## Objects in R

> In R, everything that **exists** is an object. Everything that **happens** is a function call.
- John Chambers

+ R is an object-oriented programming language. Everything is contained in an **object**, including data, analysis tools and analysis results. Things such as datasets, commands (called "functions" in R), regression results, descriptive statistics, etc., are all objects.
+ An object has a _name_ and a _value_. You create an object by **assigning** a value to a name. 
    * You assign with `<-` or with `=`.
    * R is **case-sensitive**: the object named `mydata` is different from the object named `Mydata`.
+ Whenever you run an operation or execute a function in R, you need to assign the result to an object if you want to save it and re-use it later. **Assign it or lose it**: anything that is not assigned to an object is just printed to the console and lost.
+ Objects have a size (bytes, megabytes, etc.) and a **type** (technically, a _class_, a _type_ and a _mode_ --- more on this [later](#types-and-classes-of-objects)).
+ A **function** is a particular type of object. Functions take other objects as arguments (input) and return more objects as a result (output). R functions are what other data analysis programs call "commands". See Section \@ref(functions) for more about functions.

### The workspace

+ During your R session, objects (data, results) are located in the computer's main memory. They make up your workspace: the set of **all the objects** currently in memory. They will disappear when you quit R, unless you save them to files on disk.
+ What's in your current workspace?
    * The function `ls()` shows you a full list of the objects currently in the workspace.
    * Alternatively, in RStudio open the Environment panel to get a clickable list of objects currently in the workspace (if you don't see your Environment panel, check `Preferences... > Pane Layout`).

### Saving and removing objects

+ Two main functions to **save** R objects to files: `save()` (saves specific objects, its arguments); `save.image()` (saves all the current workspace).
+ Unless you specify a different path, all files you save from R are put in your current working directory.
+ The most common file extensions for files that store R objects are `.rda` and `.RData`.
+ If you have a file with R objects, say `objects.rda`, you can **load** it in you current R session using the `load()` function: `load(file= "objects.rda")`. This assumes `objects.rda` is in your current working directory (otherwise you'll have to specify the whole file path).
+ The function `rm()` **removes** specific objects from the workspace. You can use it to clear the workspace from all existing objects by typing `rm(list=ls())` (remember that `ls()` returns a character vector with the names of all the objects in the current workspace).

```{r objects, include=TRUE, cache=FALSE, tidy=FALSE, error=TRUE}
```

### Vector and matrix objects

+ **Vectors** are the most basic objects you use in R. Vectors can be numeric (numerical data), logical (TRUE/FALSE data), or character (string data).
+ The basic function to create a vector is `c` (**concatenate**).
+ Other useful functions to create vectors: `rep` and `seq`. 
    * Another function we'll use to create vectors later in the workshop is `seq_along`. `seq_along(x)` creates a vector consisting of a sequence of integers from 1 to `length(x)` in steps of 1.
    * Also keep in mind the `:` shortcut: `c(1, 2, 3, 4)` is the same as `1:4`.
+ The **length** (number of elements) is a basic property of vectors: `length(x)` returns the length of vector `x`.
+ When we `print` vectors, the numbers in square brackets indicate the positions of vector elements.
+ To create a matrix: `matrix`. Its main arguments are the cell values (within `c()`), number of rows (`nrow`) and number of columns (`ncol`). Values are arranged in a `nrow` x `ncol` matrix _by column_. See `?matrix`.
+ When we `print` matrices, the numbers in square brackets indicate the row and column numbers.

### Data frames {#dataframes}

+ "Data frame" is R's name for dataset. A dataset is a collection of cases (rows), and variables (columns) which are measured on those cases.
+ When `print`ed in R, data frames look like matrices. However, unlike matrix columns, data frame columns can be of different types, e.g. a numeric variable and a character variable.
+ On the other hand, just like matrix columns, data frame columns (variables) must all have the same `length` (number of cases). You can't put together variables (vectors) of different length in the same data frame.
+ Although data frames look like matrices, in R's mind they are a specific kind of _list_ (more about lists in Section \@ref(lists)). In fact, the `class` of a data frame is `data.frame`, but the `type` of a data frame is `list`. The list elements for a data frame are its variables (columns).
+ **Tibbles.** The tidyverse packages, which we use in this workshop, rely on a more efficient form of data frame, called *tibble*. 
    * A tibble has class `tbl_df` *and* `data.frame`. This means that, to R, a tibble is *also* a data frame, and any function that works on data frames normally also works on tibbles. 
    * A tibble has a number of advantages over a traditional data frame, some of which we'll see in this workshop. 
    * One of the advantages is the clearer and more informative way in which tibbles are printed. When we print a tibble data frame we can immediately see its number of rows, number of columns, names of variables, and type of each variable (numeric, integer, character, etc.).
    * To convert an existing data frame to tibble: `as_tibble`. To create a tibble from scratch (similar to the `data.frame` function in base R): `tibble`.
+ While data frames can be created manually in R (with the functions `data.frame` in base R and `tibble` in `tidyverse`), data are most commonly imported into R from external sources, like a csv or txt file.
+ We'll import data from csv files using the `read_csv()` function from `tidyverse`.
    * `read_csv()` reads csv files (values separated by "," or ";"). `read_delim()` reads files in which values are separated by any delimiter. 
    * These functions have many arguments that make them very flexible and allow users to import basically any kind of table stored in a text file. Check out `?read_delim`.
    * In base R, the corresponding functions are `read.csv()` and `read.table()`.
+ Data can also be imported into R from most external file formats (SAS, SPSS, Stata, Excel, etc.) using the tidyverse packages  `readxl` and `haven`, or the `foreign` package in traditional R.
+ Note that you can click on a data frame's name in RStudio's Environment pane. That will open the data frame in a window, similar to SPSS's data view.

```{r vectors, include=TRUE, cache=FALSE, tidy=FALSE}
```

## Arithmetic, statistical, and relational operations

### Arithmetic operations and recycling

+ R can work as a normal calculator.
    * Addition/subtraction: `7+3`
    * Multiplication: `7*3`
    * Negative: `-7`
    * Division: `7/3`
    * Integer division: `7%/%3`
    * Integer remainder: `7%%3`
    * Exponentiation: `7^3`
+ Many operations involving vectors in R are performed **element-wise**, i.e., separately on each element of the vector (see examples below).
+ Most operations on vectors use the **recycling** rule: if a vector is too short, its values are re-used the number of times needed to match the desired length (see examples below).
+ Examples of vector operations and recycling:
    * `[1 2 3 4] + [1 2 3 4] = [1+1 2+2 3+3 4+4]` (element-wise addition.)
    * `[1 2 3 4] + 1 = [1+1 2+1 3+1 4+1]` (`1` is recycled 3 times to match the `length` of the first vector.)
    * `[1 2 3 4] + [1 2] = [1+1 2+2 3+1 4+2]` (`[1 2]` is recycled once.)
    * `[1 2 3 4] + [1 2 3] = [1+1 2+2 3+3 4+1]` (`[1 2 3]` is recycled one third of a time: R will warn that the length of longer vector is not a multiple of the length of shorter vector.)

### Relational operations and logical vectors

+ **Relational** operators: `>`, `<`, `<=`, `>=`. Equal is `==` (NOT `=`). _Not_ equal is `!=`.
    * Note: equal is `==`, whereas `=` has a different meaning. `=` is used to assign function arguments (e.g. `matrix(x, nrow = 3, ncol = 4)`), or to assign objects (`x <- 2` is the same as `x = 2`).
+ Relational operations result in **logical** vectors: vectors of `TRUE`/`FALSE` values.
+ Like arithmetic operations, relational ones are performed element-wise on vectors, and recycling applies.
+ Logical operators: `&` for AND, `|` for OR.
+ Negation (i.e. opposite) of a logical vector: `!`.
+ Is value _x_ in vector _y_? `x %in% y`.
+ R can convert logical vectors to numeric (`as.numeric()`, `as.integer()`). In this conversion, `TRUE` becomes `1` and `FALSE` becomes `0`. Conversely, if converted to logical (`as.logical()`), `1/0` are `TRUE/FALSE`.
    * Therefore, if `x` is a logical vector, `sum(x)` gives the _count_ of `TRUE`s in `x` (sum of `1`s in the vector).
    * `mean(x)` gives the _proportion_ of `1`s in `x` (mean of a binary vector: sum of `1`s in the vector divided by number of elements in the vector).

### Examples of arithmetic and statistical functions

+ Arithmetic _vector_ functions are performed element-wise, and return a vector. Examples:
    * Exponential: `exp(x)`.
    * Logarithm: `log(x)` (base _e_) or `log10(x)` (base 10).
+ Statistical _scalar_ functions are executed on the set of all vector elements taken together, and return a scalar. Examples: 
    * `mean(x)` and `median(x)`.
    * Standard deviation and variance: `sd(x)`, `var(x)`.
    * Minimum and maximum: `min(x)`, `max(x)`.
    * `sum(x)`: sum of all elements in `x`.
+ `table(x)` is another basic statistical function (but it's not scalar): 
    * `table(x)` returns a `table` object with the absolute frequencies of values in `x`. 
+ Functions such as `sum()`, `mean()` and `table()` are very useful when programming in R (for example, when writing your own functions). However, if you just need descriptive statistics for the data, there are more convenient tools you can use. Some of these are the following functions, which work well with `tidyverse` (we'll see them in Ch. \@ref(composition)):
    * The `skim` function (from the `skimr` package) for descriptive statistics of continuous/quantitative variables.
    * The `tabyl` function (from the `janitor` package) for frequencies of categorical variables.

### Missing and infinite values

+ Missing values in R are represented by `NA` (Not Available).
    * If your data has a different code for missing values (e.g., -99), you'll have to recode that to NA for R to properly handle missing values in your data.
+ Infinity may result from arithmetic operations: `Inf` and `-Inf` (e.g. `3/0`). `NaN` also may result, meaning Not a Number (e.g. `0/0`). 
    * While `NA`s can appear in any type of object, `Inf`, `-Inf` and `NaN` can only appear in numeric objects.
+ `is.na(x)` checks if each element of `x` is NA and returns TRUE if that's the case, FALSE otherwise. It's a vector function (its value has the same `length` as `x`).

```{r operations, include=TRUE, cache=FALSE, tidy= FALSE}
```

## Subsetting

+ **Subsetting** is crucial in R. It means extracting one (or more) of an object's elements or components, typically by appending an index (or subscript) to that object (this is also called "indexing" or "subscripting").
+ Subsetting can be used to **extract** (view, query) the component of an object, or to **replace** it (assign a different value to that element).
+ The basic notation for subsetting in R is `[ ]`: `x[i]` gives you the _i_-th element of object `x`.
+ **Numeric subsetting** uses integers in square brackets `[ ]`: e.g. `x[3]`. Note that you can use negative integers to index (select) everything _but_ that element: e.g. `x[-3]`, `x[c(-2,-4)]`.
+ **Logical subsetting** uses logical vectors in square brackets `[ ]`. It's used to subset objects based on a condition, e.g., to index all values in `x` that are greater than 3 (see example code below).
+ **Name subsetting** uses element names. Elements in a vector, and rows or columns in a matrix can have names. 
    * Names can be displayed and assigned using the `names` function in base R, or `set_names` (just to assign names) in tidyverse.
+ When subsetting you must take into account the **number of dimensions** of an object. For example, vectors have one dimension, matrices have two. Arrays can be defined with three dimensions or more (e.g. three-way tables). 
    * Square brackets typically contain a slot for each dimension of the object, separated by a comma:
        - `x[i]` indexes the _i_-th element of the one-dimensional object `x`;
        - `x[i,j]` indexes the _i,j_-th element of the two-dimensional object `x` (e.g. `x` is a matrix, _i_ refers to a row and _j_ refers to a column); 
        - `x[i,j,k]` indexes the _i,j,k_-th element of the three-dimensional object `x`, etc.
    * Notice that a dimension's slot may be empty, meaning that we index all elements in that dimension. So, if `x` is a matrix, `x[3,]` will index the whole 3rd row of the matrix -- i.e. `[`row 3, all columns`]`. 
    * If `x` has more than one dimension (e.g. it's a matrix), then `x[3]` (no comma, just one slot) is still valid, but it might give you unexpected results.
+ Matrices have special functions that can be used for subsetting, e.g. `diagonal()`, `upper.tri()`, `lower.tri()`. These can be useful for manipulating adjacency matrices.
+ Particular subsetting rules may apply to particular `class`es of objects, for example lists and data frames (see next Section \@ref(index-df)).
 
### Subsetting data frames {#index-df}

+ **List notations.** Data frames are a special class of lists (see Section \@ref(lists) for more about lists). Just like any list, data frames can be subset in the following three ways:
    1. `[ ]` notation, e.g. `df[3]` or `df["variable.name"]`. This returns another data frame that only includes the indexed element(s), e.g. only the 3^rd^ element. Note:
        - This notation _preserves the_ `data.frame` _class_: the result is still a data frame.
        - This notation can be used to index _multiple_ elements of a data frame into a new data frame, e.g. `df[c(1,3,5)]` or `df[c("sex", "age")]`
    2. `[[ ]]` notation, e.g. `df[[3]]` or `df[["variable.name"]]`. This returns the specific element (column) selected, not as a data frame but as a vector with its own type and class, e.g. the numeric vector _within_ the 3^rd^ element of `df`. Note two differences from the `[ ]` notation: 
        - `[[ ]]` _does not_ preserve the `data.frame` class. The result is _not_ a data frame.
        - Consistently, `[[ ]]` can only be used to index a _single_ element (column) of the data frame, not multiple elements.
    3. The `$` notation. If _variable.name_ is the name of a specific variable (column) in `df`, then `df$variable.name` indexes that variable. This is the same as the `[[ ]]` notation: `df$variable.name` is the same as `df[["variable.name"]]`, and it's also the same as `df[[i]]` (where `i` is the position of the variable called _variable.name_ in the data frame).
+ **Matrix notation.** Data frames can also be subset like a matrix, with the `[ , ]` notation: 
    * `df[2,3]`, `df[2, ]`, `df[ ,3]`.
    * `df[,"age"]`, `df[,c("sex", "age")]`, `df[5,"age"]`
+ **Keep in mind the difference** between the following:
    * Extracting a data frame's variable (column) in itself, as a vector (numeric, character, etc.) --- The single pepper packet by itself in the figure below (panel C). This is given by `df[[i]]`, `df[["variable.name"]]`, `df$variable.name`.
    * Extracting another data frame of just one variable (column) -- The single pepper packet _within_ the pepper shaker in the figure below (panel B). This is given by `df[i]`, `df["variable.name"]`.
+ **Subsetting verbs** in tidyverse. In addition to subsetting data frames via the base indexing syntax described above, we can also use the subsetting functions introduced by the `dplyr` package in tidyverse (see [below](#the-tidyverse-syntax)).

[![Indexing lists/data frames](./Figures/wickham_indexing_tweet.png){width=50%}](https://twitter.com/hadleywickham/status/643381054758363136?lang=en)

```{r indexing, include=TRUE, cache=FALSE, tidy= FALSE, error=TRUE}
```

## The `tidyverse` syntax

### Pipes and the `|>` operator

+ The original pipe operator, `%>%`, was introduced by the `magrittr` package in 2014. It quickly gained popularity in the R community and was adopted by `igraph` and `tidyverse` (among other packages), which we use in this workshop. In 2021, R incorporated the pipe idea with a new, similar (but not identical) operator: `|>`. See [this page](https://www.tidyverse.org/blog/2023/04/base-vs-magrittr-pipe/) for an overview of the differences between `|>` and `%>%`.
+ The idea behind pipes is in essence very simple:
    * `f(g(x))` becomes `x |> g() |> f()`.
    * For example: `mean(table(x))` becomes `x |> table() |> mean()`.
+ So `|>` pipes the output of the previous function (e.g., `table()`) into the input of the following function (e.g., `mean()`). This turns inside-to-outside code into left-to-right code. Because left to right is the direction most of us are used to read in (at least in English and other Western languages), pipes make R code easier to read and follow.
+ You may also see pipes concatenating multiple lines of code. That's possible and a common coding style. Instead of
```
x |> table() |> mean()
```
you can write 
```
x |>
  table() |>
  mean()
```

### Subsetting data frames in `tidyverse`
+ Tidyverse includes the `dplyr` package for data frame manipulation. This is a very powerful package for all kinds of data wrangling. To learn more, see the package [cheatsheet](https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf) and [vignettes](https://dplyr.tidyverse.org/articles/index.html).
+ Subsetting data frames with `dplyr`:
    * `dplyr::filter()` is used to subset rows (cases) of a data frame based on one or multiple conditions (for example, respondents with certain values on one or more variables). This preserves the data frame class, similar to `[ ]` indexing.
    * `dplyr::select()` is used to subset columns (variables) of a data frame. You can use full variable names or select variables in many other ways (see examples in the `select` [manual page](https://dplyr.tidyverse.org/reference/select.html)). This preserves the data frame class, similar to `[ ]` indexing.
    * `dplyr::pull()` is used to extract a column as a vector. This does _not_ preserve the data frame class, similar to `[[ ]]` or `$`.

```{r tidyverse, include=TRUE, cache=FALSE, tidy=FALSE, error=TRUE, message=FALSE}
```

<!--chapter:end:01_R_basics.Rmd-->

# Representing and visualizing ego-networks {#represent}


```{r include=FALSE, cache=FALSE}
knitr::read_chunk("./Scripts/03_Representing_egonets.R")
```

## Overview

After learning some basics of the R language, we now focus on R tools for egocentric network data. To make things simpler, we'll start by considering just one egocentric network. The following chapters will show you how to replicate the same type of analysis on many ego-networks at once.

This chapter covers the following topics:

* Representing ego-level attribute data and alter-level attribute data in R.
* Joining (merging) ego-level and alter-level data frames.
* Representing alter-alter tie data. 
* Representing and manipulating an ego-network as an `igraph` object.
* Visualizing an ego-network.

***

## Ego-level and alter-level data {#egocentric-data}
* In this section we use the data objects described earlier in Section \@ref(data). All these objects are stored in the `data.rda` file. In sections \@ref(egor-import) and \@ref(import-igraph) we'll show how to create these objects from raw (csv) data using `egor` and `tidyverse`.
* Egocentric network data typically include at least three types of data:
    - **Ego-level attribute data**. This is a dataset with attributes of egos. Each row is an ego (typically, a survey respondent) and each column is a characteristic of the ego. Following multilevel modeling terminology, we call this "level 2" because, in the multilevel structure of ego-network data, egos are the higher-level "groups" in which alters are clustered. In personal network surveys, these data are obtained from standard survey questions asking individual information about the respondent.
    - **Alter-level attribute data**. This is a dataset with attributes of alters and of ego-alter ties. It is also the dataset that, for each alter, indicates who is the ego who nominated that alter: that is, it lists all the ego-alter ties. In this dataset, each row is an alter and each column is a characteristic of the alter, or of the relationship between the alter and the ego who nominated him/her. Following multilevel modeling terminology, we call this "level 1" because alters are the most granular units in the data, clustered within egos. In personal network surveys, these data are obtained from the so-called _name generator_ questions, which elicit lists of alters from each ego; and from the _name interpreter_ questions, which elicit characteristics of each alter.
    - **Alter-alter tie data**. These are the data about alter-alter ties as reported by the ego. In personal network surveys, these data are obtained from so-called _edge interpreter_ questions.
* **File formats:**
    - Ego-level attribute data. This is normally a single dataset (in a single file), with each row representing one ego, and different columns representing different ego-level attributes. This is similar to any respondent-level dataset you have in standard survey data.
    - Alter-level attribute data. Depending on the data collection software, you might have a single dataset (in a single file) including alters nominated by all egos; or separate datasets (in separate files), one for each ego, with the alters nominated by that ego (and with the same variables in all datasets).
    - Alter-alter tie data. These are typically in edge list format or in adjacency matrix format, depending on the data collection software. If the tie data are in adjacency matrices, you normally have a separate adjacency matrix for each ego, in a separate file. If they are in edge lists, you might have a single edge list including alters from all egos (with an additional column indicating the ego that nominated the two alters), or a separate edge list (in a separate file) for each ego.
* The data format described above works well because, in standard egocentric data, the different ego-networks are **separate** (non-overlapping). This means that an alter can only "belong" to one and one only ego, and alter-alter ties only exist between alters nominated by the same egos. In other words, there are no links or overlaps between the networks of different egos. 
    - In particular, this means that there is a one-to-one correspondence between alters and ego-alter ties: for each ego-alter tie there is only one alter, and vice versa (so the level of alters is the same as the level of ego-alter ties).
* In egocentric analysis you are frequently switching between level 1 and 2, and **joining** information from the two levels.
* **Level-1 join.** Bring information from level 2 into the level-1 dataset.
    - For certain types of analysis you need to join ego attributes (level 2) into an alter-level data set (level 1).
    - For example, you need to do this when estimating multilevel models in which the dependent variable is a characteristic of ego-alter ties (e.g., if the tie provides support), and some of the predictors are ego-level characteristics (e.g., gender of the ego).
    - Because there is one ego for multiple alters, this is a one-to-many join, with the same value of an ego attribute (one ego row in the level-2 dataset) being joined to multiple alters (multiple alter rows in the level-1 dataset).
    - The data frames are joined by ego ID. 
* **Level-2 join.** Bring information from level 1 into the level-2 dataset.
    - In other cases you want to join alter attributes (level 1) into an ego-level dataset (level 2). 
    - For example, you need to do this when you want to analyze summary measures of ego-network characteristics (e.g. average age of alters) among the egos.
    - Because there are multiple alters for one ego, this requires that you first summarize or aggregate the alter attributes for each ego.
    - If you have _continuous_ alter attributes, you typically summarize them by taking averages and dispersion measures (variance, standard deviation, etc.) of the alter attribute for each ego: for example, average alter age for each ego, or standard deviation of contact frequency between alters and each ego.
    - If you have _categorical_ alter attributes, you normally summarize them by taking counts or proportions of certain categories, or qualitative diversity measures (e.g., generalized variance, entropy): for example, proportion of women, or ethnic diversity in each ego's network.
    - Once you have these summary variables on ego-network _composition_, you can join them with an ego-level dataset by ego ID.
    - The level-2 join can also involve summary variables on ego-network *structure*: for example, average alter degree, ego-network density, or number of components. These variables can be joined with an ego-level dataset by ego ID.
    - We'll consider this type of ego-level summarization and the level-2 join in Chapters \@ref(composition) and \@ref(structure) about measures of ego-network composition and structure.
* In base R, data frames can be joined using the `merge` function. However, we use the `dplyr` join functions, whose code is more efficient and readable:
    - `left_join()` retains all rows in the *left* data frame, and discards any row in the right data frame that does not have a match with a row in the left data frame.
    - `right_join()` retains all rows in the *right* data frame, and discards any row in the left data frame that does not have a match with a row in the right data frame.
    - `full_join()` retains all rows from both data frames.
* McCarty and colleagues (2019) provide a more detailed discussion of all types of egocentric network data, levels in egocentric data, and switching and joining operations between levels.
+ **What we do in the following code**.
    * View ego-level data (level 2) and alter-level data (level 1) as stored in R data frames.
    * Do the level-1 join: Bring ego attributes into an alter-level data frame.

```{r levels, include=TRUE, cache=FALSE, tidy= FALSE}
```

## Networks in R

+ There are several packages for network analysis in R. The two main (collections of) R network packages are `igraph` and `statnet`. `igraph` is a single package. It represents networks as objects of class `igraph`. `statnet` is not a package, it's a collection of packages. It represents networks as objects of class `network`. 
+ `igraph` and `statnet` are in part overlapping, in part complementary. Historically, `igraph` has focused more on network methods developed in computer science and physics, while `statnet` has emphasized network methods developed in statistics and the social sciences. Many things can be done in _both_ `igraph` and `statnet`: basic network creation, importing network data, network manipulation, basic network metrics such as centrality, and network visualization. On the other hand, a few things can only be done in `igraph` (e.g., "community detection" algorithms and modularity analysis), and others can only be done in `statnet` (e.g., ERGMs). 
+ Most of this workshop uses the package `igraph`. This is because I personally find `igraph`'s syntax more intuitive for beginners, especially for simple operations on networks. In Chapter \@ref(statnet) we'll also briefly demonstrate how networks are represented in `statnet`'s `network` objects. You should keep in mind that everything we'll do here with `igraph`, can also be done with `statnet`. In general, you'll need to learn about `statnet` too if you want to master a complete toolkit for social network analysis with R.
+ We'll also briefly use the `ggraph` package for network visualization and the `tidygraph` package for easier display and manipulation of networks. We don't have time to go into much detail about these two packages, but you can find more tutorials and learning resources about them online.
    * `ggraph` flexible and easy tools for network visualization by applying the [`ggplot2` grammar](https://ggplot2.tidyverse.org/) of graphics to network data (learn more [here](https://github.com/thomasp85/ggraph)). In addition to `ggraph`, you can also visualize networks with `igraph`, which uses base R plotting (see Section \@ref(more-igraph)).
    * `tidygraph` applies the `tidyverse` principles of [tidy data](https://r4ds.had.co.nz/tidy-data.html) to networks. This allows you to easily view and manipulate the basic components of network data in tabular format, i.e., edge data as an edge list and node attribute data as a case-by-variable dataset. More information about `tidygraph` is [here](https://www.data-imaginist.com/2017/introducing-tidygraph/).

## Ego-networks as `igraph` objects

+ In `igraph`, networks are called **graphs** and are represented by objects of class `igraph`. Nodes are called **vertices** and ties are called **edges**.
+ Given an igraph object `gr`:
    * `V(gr)` shows you the graph vertices (identified by `name`, if they have a `name` attribute, or by integers otherwise). This is an object of class _vertex sequence_ (`igraph.vs`).
    * `E(gr)` shows you the graph edges. This is an object of class _edge sequence_ (`igraph.es`).
+ Vertices, edges and graphs have **attributes**. You can import them from external data files, or you can set them manually in R. If you import data into an `igraph` object with a vertex attribute called "age", an edge attribute called "strength", and a graph attribute called "size", then
    * `V(gr)$age` returns the vertex attribute `age` as a vector; 
    * `E(gr)$strength` returns the edge attribute `strength` as a vector; 
    * `gr$size` returns the graph attribute `size`.
+ `print`ing an `igraph` object returns some **summary information** about the network. This includes the counts of vertices and edges, and whether the network is directed, named (i.e. if vertices have a `name` attribute), weighted (i.e. if edges have a `weight` attribute), or bipartite (also called two-mode).
+ **Querying vertices and edges**
    * Based on attributes. You can query vertices and edges with specific characteristics (attribute values), and save them for re-use. E.g. `V(gr)[age=30]` returns all vertices whose `age` attribute equals 30; `E(gr)[strength=1]` returns all edges whose strength is 1.
    * Based on network structure. The `V(gr)[...]` and `E(gr)[...]` syntax can also be used with specific functions that extract information on tie distribution: for example, to query all vertices that are adjacent to a given vertex _i_, or all edges between two particular subsets of vertices. The main functions here are `nei()`, `inc()` and `%--%` (see code below).
    * More information on useful igraph syntax for vertex and edge indexing is [here](http://igraph.org/r/doc/igraph-vs-indexing.html) (vertex indexing) and [here](http://igraph.org/r/doc/igraph-es-indexing.html) (edge indexing).
+ **What we do in the following code**.
    * View an ego-network as an `igraph` object.
    * View vertex and edge attributes in an ego-network.
    * Obtain descriptive statistics for attributes of alters (vertex attributes) and alter-alter ties (edge attributes) in the ego-network.
    * Visualize an ego-network with `ggraph`, setting aesthetic parameters based on alter attributes.
    * Query vertices and edges based on attributes.

```{r igraph, include=TRUE, cache=FALSE, tidy= FALSE, out.width = "60%", fig.align="center", message=FALSE, warning=FALSE}
```

<!--chapter:end:02_Representing_egonets.Rmd-->

# Ego-network composition {#composition}


```{r include=FALSE, cache=FALSE}
knitr::read_chunk("./Scripts/04_Composition.R")
```

## Overview

Ego-network composition refers to the distribution of attributes of alters (for example, age and race/ethnicity) or attributes of ties between alters and the ego (for example, closeness or frequency of contact). For brevity, these are often called simply _alter attributes_ in the following text. Recall that, in typical egocentric network data, the level of alters is the same as the level of ego-alter ties: for each alter there is one and only one ego-alter tie, and vice versa. Like in other chapters, we consider composition by first analyzing just one ego-network, then replicating the same type of analysis on many ego-networks at once.

This chapter covers the following topics:

* Calculating measures of composition for one ego-network.
* Representing data from multiple ego-networks as data frames.
* Running the same operation on many ego-networks and combining results back together (split-apply-combine).
* Split-apply-combine on data frames with `dplyr` to analyze the composition of many ego-networks at once.

***

## Measures of ego-network composition
* Many different measures can be calculated in R to describe ego-network composition. 
    - The result is typically an ego-level summary variable: one that assigns a number to each ego, with that number describing a characteristic of the ego-network composition for each ego.
* To calculate compositional measures we don't need any network or relational data (data about alter-alter ties), we only need the alter-level attribute dataset (for example, with alter age, gender, ethnicity, frequency of contact, etc.). In other words, we only need, for each ego, a list of alters with their characteristics, and no information about ties between alters.
    - So in this section, ego-networks are represented simply by alter-level data frames. We don't need to work with the `igraph` network objects until we want to analyze ego-network structure (alter-alter ties).
* There are at least three types of compositional measures that we may want to calculate on ego networks. All these measures are calculated for each ego.
    - Measures based on _one attribute_ of alters. For example, average alter age in the network.
    - Measures based on _multiple attributes_ of alters. For example, average frequency of contact (attribute 1) between ego and alters who are family members (attribute 2).
    - Measures of _ego-alter homophily_. These are summary measures of the extent to which alters are similar to the ego who nominated them, with respect to one or more attributes. For example, the proportion of alters who are of the same gender (ethnicity, age bracket) as the ego who nominated them.
+ **What we do in the following code**.
    * Look at the alter attribute data frame for one ego.
    * Using this data frame, calculate compositional measures based on one alter attribute.
    * Calculate compositional measures based on two alter attributes.
    * Do the level-1 join: join ego attributes into alter-level data.
    * Using the joined data, calculate compositional measures of homophily between ego and alters.
    * Calculate multiple compositional measures and put them together into one ego-level data frame.

```{r composition, include=TRUE, cache=FALSE, tidy= FALSE}
```

## Analyzing the composition of many ego-networks {#comp-many}

### Split-apply-combine in egocentric network analysis

+ Now that we've learned how to represent and analyze data on one ego-network, we're ready to scale these operations up to a *collection* of many ego-networks.
+ Often in social science data analaysis (or any data analysis), our data are in a single file, dataset or object, and we need to:
    1. _Split_ the object into pieces based on one or multiple (combinations of) categorical variables or factors.
    2. _Apply_ exactly the same type of calculation on each piece, identically and independently.
    3. _Combine_ all results back together, for example into a new dataset.
+ This has been called the **split-apply-combine** strategy [@wickham_split-apply-combine_2011] and is essential in egocentric network analysis. With ego-networks, we are constantly (1) splitting the data into pieces, each piece typically corresponding to one ego; (2) performing identical and independent analyses on each piece (each ego-network); (3) combining the results back together, typically into a single ego-level dataset, to then associate them with other ego-level variables.
+ In base and traditional R, common tools to perform split-apply-combine operations include `for` loops, the `apply` family of functions, and `aggregate`.
+ The `tidyverse` packages provide new ways of conducting split-apply-combine operations with more efficient and readable code:
    * Grouping and summarizing data frames with the `dplyr` package. This is particularly relevant to ego-network composition (next [section](#summarize-dplyr)).
    * Applying the same function to all elements in a list with the `map` family of functions in the `purrr` package. This is more relevant to ego-network structure (see Section \@ref(apply-purrr))

### Grouping and summarizing with `dplyr` {#summarize-dplyr}
+ Whenever we have a dataset in which rows (level 1) are clustered or grouped by values of a given factor (level 2), the package `dplyr` makes level-2 summarizations very easy. 
    * In egocentric analysis, we typically have an alter attribute data frame whose rows (alters, level 1) are clustered by egos (level 2).
+ In general, the `dplyr::summarise` function allows us to calculate summary statistics on a single variable or on multiple variables in a data frame. 
    * To calculate the same summary statistic on multiple variables, we select them with `across()`.
+ If we run `summarise` after _grouping_ the data frame by a factor variable with `group_by`, then the data frame will be "split" by levels (categories) of that factor, and the summary statistics will be calculated on each piece: that is, for each unique level of the grouping factor. 
    * So if the grouping factor is the ego ID, we can immediately obtain summary statistics for each of hundreds or thousands of egos in one line of code. The code below provides examples.
+ **What we do in the following code**. 
    * Use `summarise` to calculate summary variables on network composition for all of the 102 egos at once.
    * Join the results with other ego-level data (level-2 join).

```{r split-df, include=TRUE, cache=FALSE, tidy= FALSE}
```

<!--chapter:end:03_Composition.Rmd-->

# Ego-network structure {#structure}

```{r include=FALSE, cache=FALSE}
knitr::read_chunk("./Scripts/05_Structure.R")
```

## Overview 

Ego-network structure refers to the distribution of ties among alters. As usual, we first illustrate analyses on one ego-network, then replicate them on many ego-networks at once.

This chapter covers the following topics:

* Calculating measures of ego-network structure.
* R lists and how they can be used to represent many ego-networks.
* Split-apply-combine on lists with `purrr` to analyze the structure of many ego-networks at once.

***

## Measures of ego-network structure
* Ego-network structure can be described using different measures, either at the alter level (e.g., alter centrality measures) or at the ego level (e.g., ego-network density).
* Some of these structural measures are calculated on the alter-alter network *excluding* the ego. Other measures (e.g., ego betweenness, constraint) are calculated on the ego-network *including* the ego. We will see examples of both.
* Certain measures combine information about both structure and composition: they are based on data about both the distribution of alter-alter ties and the distribution of alter attributes. An example is the average degree centrality (network structure) of alters who are family members (network composition).
* Note that whenever ego-network structure is considered (whether by itself or in combination with composition), we need data on alter-alter ties. Unlike in Chapter \@ref(composition), just the alter attribute data frame will not be sufficient.
    - So in this section we need to work with the `igraph` objects containing the alter-alter tie information for our ego-networks (and possibly also incorporate alter attribute data frames if our measures are a combination of structure and composition).
* **What we do in the following code**.
    * Consider ego-network structural measures based on the distribution of alter-alter ties, with the ego excluded: density, number of components, average alter degree, maximum alter betweenness, number of isolates. Calculate these using `igraph` functions.
    * Consider structural measures that require the ego to be included in the `igraph` object: ego betweenness, constraint. Calculate these with `igraph`.
    * Calculate measures combining ego-network structure and composition: type of relationship between ego and the most between-central alter; average degree centrality of alters who are family members; density of ties among alters in certain categories (e.g., alters who live in Sri Lanka).

```{r structure, include=TRUE, cache=FALSE, tidy= FALSE, message=FALSE}
```

## R lists {#lists}

+ A lists is simply a **collection** of objects. It can contain any kind of object, with no restriction. A list can contain other lists.
+ Lists have `list` as `type` _and_ `class`.
+ Data frames are a type of list. Other complex objects in R are also _stored_ as lists (have `list` as `type`), although their `class` is not `list`: for example, results from statistical estimations or network community detection procedures.
+ Use `str(list)` to display the types and lengths of elements in a list.
+ List may be _named_, that is, have element names. You can view or assign names with the `names` function (base R) or the `set_names` function (tidyverse).
+ **Three different notations to index lists**:
    1. `[ ]` notation, e.g. `my.list[3]`. 
    2. `[[ ]]` notation, e.g. `my.list[[3]]` or `my.list[["element.name"]]`. 
    3. The `$` notation. This only works for named lists. E.g., `list$element.name`. This is the same as the `[[ ]]` notation: `list$element.name` is the same as `list[["element.name"]]` or `list[[i]]` (where `i` is the position of the element called _element.name_ in the list).
+ These three indexing methods work in exactly the same way as for data frames (see Section \@ref(index-df)).
+ **What we do in the following code**. 
    * Create, display, and index a list.

```{r lists, include=TRUE, cache=FALSE, tidy= FALSE}
```

## Analyzing the structure of many ego-networks {#apply-purrr}
+ In base R, functions of the `apply` family, such as `lapply` and `sapply`, are the traditional way to take a function and apply it to every element of a list. In tidyverse, the `purrr` package does the same thing but in more efficient ways and with more readable code. 
+ We use `purrr` to apply the same function to each element of a list of ego-networks, that is, to each ego-network. Depending on the function, the result for each ego-network may be a single number or a more complex object (for example, a data frame).
+ `purrr` provides type-stable functions, which always return the same type of output: 
    * `map` always returns a list. (This is the equivalent of `lapply` in base R).
    * `map_dbl` always returns a vector of double-precision numbers. `map_int` returns a vector of integer numbers. `map_chr` returns a character vector. `map_lgl` returns a logical vector.
    * `map_dfr` returns a data frame. It assumes that you are applying an operation to each list element, which returns one data frame row for that element. It then binds together the data frame rows obtained for each element, combining them into a single data frame.
+ In addition to type-stable output, the `map` functions also offer a convenient formula syntax: `~ f(.x)`, where: (1) `.x` represents each element of the input list; (2) `f` is the function to be executed on that element.
    * For example, `map(L, ~ .x * 2)` takes each element of the list `L` (represented by `.x`) and multiplies it times 2.
+ The `map` functions preserve list names in their output. If we have a list of ego-networks whose names are the ego IDs, this means that ego IDs will be preserved in result lists and vectors.
+ `map` is also useful when you want to run functions that take a list element as argument (e.g. an `igraph` ego-network), and return another list element as output (e.g. another `igraph` object). This is the case whenever you want to manipulate the ego-networks (for example, only keep a certain type of ties or vertices in the networks) and store the results in a new list.
+ `map_dbl` is useful when you want to run functions that take a list element as argument (e.g. an `igraph` ego-network), and return a number as output. This is the case whenever you want to run a structural measure such as tie density or centralization on each network.
+ **What we do in the following code**. 
    * Use `purrr` functions to calculate the same structural measures on every ego-network in the data.

```{r split-list, include=TRUE, cache=FALSE, tidy= FALSE}
```

<!--chapter:end:04_Structure.Rmd-->

# Multilevel modeling of ego-network data {#multilevel}

```{r include=FALSE, cache=FALSE}
knitr::read_chunk("./Scripts/06_Multilevel.R")
```

In progress.

## Resources

### Multilevel models for egocentric network data

Specific resources on multilevel modeling of egocentric/personal network data:

* [@vacca_multilevel_2018](https://www.sa-ijas.org/ojs/index.php/sa-ijas/article/view/30-3): overview of multilevel modeling for egocentric/personal network data, with R demo (the code below is drawn in part from this article).
* @simonoff_multilevel_2013: overview of multilevel modeling for egocentric and sociocentric data.
* [@vacca_cross-classified_2019](http://journals.sagepub.com/doi/10.1177/0049124119882450): multilevel models for overlapping egocentric networks.
* @mccarty_conducting_2019: Ch. 13.
* @perry_egocentric_2018: Ch. 8.
* @crossley_social_2015: Ch. 6.

### Multilevel modeling in general

General resources on multilevel models:

* [@rasbash_lemma:_2008](https://www.cmm.bris.ac.uk/lemma): Extensive online course on multilevel modeling for the social sciences, including Stata and R implementation.
* @snijders_multilevel_2012: mode in-depth statistical treatment, social science focus.
* @goldstein_multilevel_2010
* @fox_r_2018: Ch. 7, R implementation with `lme4`.
* [GLMM FAQ](http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html) by Ben Bolker and others: online list of R packages and resources on linear and generalized linear mixed models.

## Prepare the data

```{r mm-setup, include=TRUE, cache=FALSE, tidy= FALSE, message=FALSE}
```

## Random intercept models

```{r rand-intercept, include=TRUE, cache=FALSE, tidy= FALSE}
```

## Random slope models

```{r rand-slope, include=TRUE, cache=FALSE, tidy= FALSE}
```

## Tests of significance

```{r test-sign, include=TRUE, cache=FALSE, tidy= FALSE}
```

<!--chapter:end:05_Multilevel.Rmd-->

# The `egor` package {#egor}

```{r include=FALSE, cache=FALSE}
knitr::read_chunk("./Scripts/07_egor.R")
```

The `egor` package provides tools for data import, data manipulation, network measures and visualization for egocentric network analysis. This chapter currently focuses on egocentric data import, with Section \@ref(egor-import) showing how we can use `egor` to read raw csv files into the R data objects used throughout this workshop (those saved in the `data.rda` file). 

More information about this package can be found in its [github website](https://github.com/tilltnet/egor) and [main vignette](https://cran.r-project.org/web/packages/egor/vignettes/using_egor.html). A list of all `egor` vignettes is [here](https://cran.r-project.org/web/packages/egor/index.html).

## Importing ego-network data {#egor-import}

* Here we show how to use `egor` to import egocentric data stored in csv files. This operation requires that all needed csv files are first imported into R data frames, using standard data import functions such as `read_csv()`. The `egor` functions then take these data frames as input and return an `egor` object as output. 
* Once we have the data in an `egor` object, this can be manipulated and analyzed in various and powerful ways. It can also further be converted into the other types of objects we have used throughout this workshop, such as a data frame of alter attributes or a list of igraph objects.
* In this example, we import the data with the function `threefiles_to_egor`. This assumes that the data are stored in three datasets: (1) a datasets with ego attributes for all egos; (2) a datasets with attributes of the alters and ego-alter ties, for all alters from all egos; (3) a datasets of alter-alter ties with a single edge list for all alters from all egos. These correspond to the three main components of egocentric data discussed in Section \@ref(egocentric-data): (1) ego attributes; (2) alter attributes; (3) alter-alter ties.
* In some cases, these three components are combined into two or even one single dataset. `egor` offers functions to import data in these formats as well: `onefile_to_egor` and `twofiles_to_egor`. See their manual page for the contents and features that the functions assume in these data. 
* Finally, `egor` has functions to import egocentric data obtained from popular data collection software, such as `read_openeddi`, `read_egoweb`, and `read_egonet`.
* Regardless of the format of the original data, an `egor` object always stores the data in the three components indicated above (ego attributes, alter attributes, alter-alter ties). Each of the three components can be "activated" using the `activate` function, similar to the `tidygraph` package. After we select which of the three components we want to work on (via `activate`), an `egor` object can be easily manipulated with `dplyr` verbs.
* **What we do in the following code**.
    - Read three csv files (ego attributes, alter attributes, alter-alter ties) into R data frames.
    - Create an `egor` object from these three data frames.
    - Convert the `egor` object to a list of `igraph` ego-networks.
* The resulting data objects are those that we used in the previous chapters (saved in the `data.rda` file).

```{r egor, include=TRUE, cache=FALSE, tidy= FALSE, message=FALSE}
```

## Analyzing and visualizing ego-network data 

In progress.

`egor` also simplifies some of the analysis operations that we have seen in the previous chapters, such as the calculation of certain compositional and structural measures.

<!--chapter:end:06_egor.Rmd-->

# Supplementary topics {#supplementary}

```{r include=FALSE, cache=FALSE}
knitr::read_chunk("./Scripts/08_Supplementary.R")
```

## More R programming topics  

### Types and classes of objects

This is a quick summary of the basics about **types** and **classes** of objects in R.

+ Three functions are used to know what kind of object you are dealing with in R: `class()`, `mode()`, and `typeof()`.
+ For most purposes, you only need to know what the **class** of an object is. This is returned by `class()`. The class of an object determines what R functions you can or cannot run on that object, and how functions will behave when you run them on the object. In particular, if the function has a `method` for a specific class _A_ of objects, it will use that method whenever an object of class _A_ is given as its argument.
+ `typeof()` and `mode()` return the **type** and **mode** of an object, respectively. Although they refer to slightly different classifications of objects, type and mode give essentially the same kind of information --- the type of data structure in which the object is stored, also called the R "internal type" or "storage mode". For example, an object can be internally stored in R as double-precision numbers, integer numbers, or character strings. 
    * You should prefer `typeof()` over `mode()`. `mode()` refers to the old S classification of types and is mostly used for S compatibility.
+ While most times all you need to know is the `class` of an object, there are a few cases in which knowing the `type` is useful too. For example, you may want to know the `type` of a matrix object (whose `class` is always `matrix`) to check if the values in the matrix are being stored as numbers or character strings (that will affect the result of some functions).

+ Main classes/types of objects
    * `numeric`: Numerical data (integer, real or complex numbers).
    * `logical`: `TRUE/FALSE` data.
    * `character`: String data.
    * `factor`: Categorical data, that is, integer numbers with string labels attached. May be _unordered_ factors (nominal data) or _ordered_ factors (ordinal data).

+ Special and complex classes/types
    * `list`: A collection of elements of any type, including numeric, character, logical (see Section \@ref(lists)).
    * `data.frame`: A dataset. In R, a data frame is a special kind of list (its type is `list` but its class is `data.frame`), where each variable (column) is a list element (see Section \@ref(dataframes))
    * `matrix`: Matrix values can be numeric, character, logical etc. So an object can have `matrix` as class and `numeric`, `character` or `logical` as type. While data frames can contain variables of different type (e.g. a character variable and a numeric variable), matrices can only contain values of _one_ type.
    * Functions (more on this in Section \@ref(functions)).
    * Expressions.
    * Formulas.
    * Other objects: Statistical results (e.g. linear model estimates), dendrograms, graphics objects, etc.
+ Relevant functions
    * `class()`, `typeof()` and `mode()`, as discussed above.
    * `is.`_type_ functions verify that an object is in a specific type or class: e.g. `is.numeric(x)`, `is.character(x)` (they return `TRUE` or `FALSE`).
    * `as.`_type_ functions convert objects between types or classes: e.g. `as.numeric()`, `as.character()`. If the conversion is impossible, the result is `NA`: e.g. `as.numeric("abc")` returns `NA`.

```{r types, include=TRUE, cache=FALSE, tidy= FALSE}
```

### Writing your own R functions {#functions}

+ One of the most powerful tools in R is the ability to **write your own functions**.
+ A function is a **piece of code** that operates on one or multiple **arguments** (the _input_), and returns an _output_ (the function  **value** in R terminology). Everything that happens in R is done by a function. 
+ Many R functions have **default values** for their arguments: if you don't specify the argument's value, the function will use the default.
+ Once you write a function and define its arguments, you can run that function on any argument values you want --- provided that the function code actually works on those argument values. For example, if a function takes an `igraph` object as an argument, you'll be able to run that function on any network you like, provided that the network is an `igraph` object. If your network is a `network` object (created by a `statnet` function), the function will likely return an error.
+ R functions, combined with [functional](https://adv-r.hadley.nz/functionals.html) and summarization methods such as those seen in Sections \@ref(comp-many) and \@ref(apply-purrr), are the best way to run exactly the same code on many different objects (for example, many different ego-networks). Functions are  **crucial for code reproducibility** in R. If you write functions, you won't need to re-write (copy and paste) the same code over and over again --- you just write it once in the function, then run the function any time and on any arguments you need. This yields clearer, shorter, more readable code with less errors.
+ New functions are also commonly used to  **redefine existing functions** by pre-setting the value of specific arguments. For example, if you want all your plots to have `red` as color, you can take R's existing plotting function `plot`, and wrap it in a new function that always executes `plot` with the argument `col="red"`. Your function would be something like  `my.plot <- function(...) {plot(..., col="red")}` (examples below).
+ **Tips and tricks** with functions:
    * `stopifnot()` is useful to check that function arguments are of the type that was intended by the function author. It stops the function if a certain condition is not met by a function argument (e.g. argument is _not_ an `igraph` object, if the function was written for `igraph` objects).
    * `return()` allows you to explicitly set the output that the function will return (clearer code). It is also used to stop function execution earlier under certain conditions. Note: If you don't use `return()`, the function value (output) is the last object that is printed at the end of the function code.
    * `if` is a flow control tool that is frequently used within functions: it specifies what the function should do `if` a certain condition is met at one point.
    * First think particular, then generalize. When you want to write a function, it's a good idea to first try the code on a "real", specific existing object in your workspace. If the code does what you want on that object, you can then wrap it into a general function to be run on any similar object (see examples in the code below).
+ In ego-network analysis, we often want to write functions that calculate measures of ego-network composition and structure that we are interested in. These functions will have different arguments depending on whether they look at network composition or structure:
    * Functions that calculate compositional measures typically require just the alter attribute data frame as argument.
    * Functions that calculate structural measures require the ego-network as an `igraph` object (or `network` object in `statnet`), which store the alter-alter tie information.
    * Functions that calculate measures combining composition and structure require the `igraph` object, with alter attributes incorporated in the object as vertex attributes.
+ **What we do in the following code**.
    * Demonstrate the basics of R functions using simple examples.
    * Consider some of the compositional and structural measures we calculated in previous chapters, and convert them to general functions that can be applied to any ego-network: average closeness of alters; proportion of female alters; proportion of alters of the same gender as ego; function that returns multiple compositional measures into a data frame; maximum alter betweenness; number of components and isolates in the ego-network; tie density between alters who live in Sri Lanka.

```{r functions, include=TRUE, cache=FALSE, tidy=FALSE, error=TRUE}
```

## Importing ego-network data with `igraph` and `tidyverse` {#import-igraph}

This section demonstrates how to import ego-network data into R "manually", without using `egor`. The `egor` packages has simplified many of these operations (see Section \@ref(egor)).

### Importing data for one ego-network
* Different functions exist to create `igraph` objects from data manually typed in R or (more typically) imported from external data sources -- such as adjacency matrices or edge lists in an external csv file. Some of these functions are `graph_from_edgelist`, `graph_from_adjacency_matrix`, `graph_from_data_frame`.
* The following code assumes a common format for egocentric data (which, however, may not be the one you have): (1) a dataset with ego attributes for all egos; (2) a dataset with alter attributes for all alters from all egos; (3) a dataset of alter-alter ties with a single edge list for all alters from all egos.
+ **What we do in the following code**.
    * Import an ego-network from 2 csv files: the csv file with the edge list (alter-alter ties) and the csv file with alter attributes for one ego. Convert it to igraph object with alter attributes: `graph_from_data_frame()`.

```{r import_1, include=TRUE, cache=FALSE, tidy= FALSE}
```

### Importing data on many ego-networks as data frames and lists
+ **Lists** are very convenient objects to store multiple pieces of data, such as multiple adjacency matrices or multiple alter attribute data frames, one for each ego. Once we have all our data pieces (e.g. matrices or data frames) into a single list, we can very easily do two things:
    * Run a function on _every_ piece in batch (see Sections \@ref(comp-many) and \@ref(apply-purrr)).
    * Run a function on _all_ the pieces together, using `do.call()`. `do.call(function, list)` executes `function` using all the elements of `list` as its arguments.
+ In many cases, attributes of all alters from all the egos are stored in a single tabular dataset, e.g., a single csv file (such as `alter_attributes.csv` in our data). Alter tie data can also be stored in a single csv file, for example as an edge list with an additional column indicating the ego ID (such as `alter_ties.csv` in our data). Data of this type can be easily imported into R using the `read_csv` function in tidyverse.
+ In other cases, alter attributes or alter-alter edge lists are stored in different `csv` files, one for each ego. These can also be imported using `read_csv()` within a `for` loop. 
+ Regardless of the external csv data source, once the data are in R we might want to store them as a single *data frame* with all alters from all egos, or as a *list*  of separate data frames, one for each ego.
    * While a single data frame is more compact, there are scenarios in which coding is simpler if data for different egos are located in different data frames, and all these data frames are gathered in a list.
+ In R it is easy to switch between a single data frame (pooling alters from all egos) and a list (with alters from each ego in a separate data frame)
    * Separate data frames, say `df1` and `df2`, can be appended into a single data frame using `bind_rows`, which stacks their rows together: e.g. `bind_rows(df1, df2)`. If we have 100 egos, we will want to bind 100 data frames. If the data frames are part of a list, say `df.list`, this can be done simply as `bind_rows(df.list)`. The result is a single data frame in which all data from all egos are stacked together by rows. Note that this requires that all data frames in `df.list` have the same variables with the same names.
    * A single data frame, say `df` can be split into a list of data frames (one for each ego) by running `split(df, f= df$egoID)` -- where `df$egoID` is the variable with the ego IDs. This splits the single data frame into a list of separate data frames, one for each value of `egoID` (i.e., one for each ego).
+ When you store ego data frames into a list, ego IDs can be conveniently saved as **names of list elements** (set via `names` or `set_names`). If you're using _numeric_ ego IDs, you should be careful to the order in which list elements are stored in the list. Depending on the sequence of your numeric ego IDs, the 53rd data frame in the list is not necessarily the data frame of ego ID=53. Thus, you need to keep in mind the difference between `list[[53]]` (numeric indexing: get the 53rd list element) and `list[["53"]]` (name indexing: get the list element named "53").
+ **What we do in the following code**. 
    * Import the alter attribute data frame and edge list for all alters from `alter_attributes.csv` and `alter_ties.csv`.
    * Demonstrate how alter attribute data frames and edge lists can be easily split by ego (using `split`) or combined into a single data frame with all alters (using `bind_rows`).

```{r import_2, include=TRUE, cache=FALSE, tidy= FALSE}
```

### Creating lists of ego-networks as `igraph` objects with `purrr`
+ `purrr::map()` is useful when you want to run functions that take a list element as argument, e.g. an `igraph` ego network; and return another list element as output, e.g. another `igraph` object. This is the case whenever you want to manipulate the ego networks (e.g. only keep a certain type of ties or vertices), and store the results in a new list.
+ In certain cases, you want to run a function that takes *two* arguments from two different lists, say `L1` and `L2`, for each ego. For example, for each ego you may want to take its alter-alter edge list (argument 1, from `L1`), take its alter attributes (argument 2, from `L2`), and put them together into an `igraph` object. 
    * The function `purrr::map2()` does this with very little code. For `i`= 1, ..., *I*, `map2()` takes the `i`-th element of `L1` and the `i`-th element of `L2`, and runs your function *I* times, one for each pair of arguments `L1[[i]]` and `L2[[i]]`.
    * Note that `L1` and `L2` need to be two "parallel" lists: the first element of `L1` corresponds to (will be combined with) the first element of `L2`; the second element of `L1` with the second element of `L2`, ..., the *I*-the element of `L1` with the *I*-th element of `L2`.
    * `map2()` has a formula notation too: `map2(L1, L2, ~ f(.x, .y)`, where `.x` refers to each element of `L1` and `.y` refers to each element of `L2`.
+ **What we do in the following code**.
    * Use `map()` to convert each ego's edge list to an `igraph` object.
    * Use `map2()` to convert each ego's edge list *and* alter attribute data frame to an `igraph` object.

```{r import_3, include=TRUE, cache=FALSE, tidy= FALSE}
```

## More operations with `igraph` {#more-igraph}

* More examples of network visualization with `igraph`.
* Add vertices to `igraph` objects, for example to add the ego node.

```{r more_igraph, include=TRUE, cache=FALSE, tidy= FALSE}
```

## The `statnet` suite of packages {#statnet}
* `statnet` is a collection of different packages. The `statnet` packages we'll use in the following code are `network` and `sna`.
* While `igraph` represents networks as objects of class `igraph`, `statnet` represents networks as objects of class `network`.
* If your network is already stored in an `igraph` object but you want to analyze it with `statnet`, you can easily convert the `igraph` object into a `network` object using the `intergraph` package (function `asNetwork()`). The conversion preserves edge (adjacency) data, vertex attributes, edge attributes, and network attributes.
* Of course, you can also create a `network` object from external data, such as an adjacency matrix stored in a csv file.
* Similar to `igraph`, `statnet` allows you to import, set and view edge, vertex, and network attributes in addition to edge (adjacency) data.
* `igraph` and `statnet` have overlapping function names. That is, there are `igraph` functions and `statnet` functions that have the same name, although they are obviously different functions. For example, both `igraph` and `statnet` have a function called `degree` to calculate vertex degree centrality. When both `igraph` and `statnet` are loaded, you should use the `package::function()` notation to specify which package you want to take the function from (see Section \@ref(starting-R-and-loading-packages)). 

```{r statnet, include=TRUE, cache=FALSE, tidy= FALSE, error=TRUE, message=FALSE}
```

## Illustrative example: personal networks of Sri Lankan immigrants in Italy

In this section, we'll apply some of the tools presented earlier to a specific case study about the personal networks of Sri Lankan immigrants in Italy. We will demonstrate the use of R in four major tasks of personal network analysis:

1. **Visualization**. We'll write an R function that plots a personal network with specific graphical parameters. We'll then run this function on many personal networks and we'll export the output to an external pdf file.

2. **Compositional analysis**. We'll calculate multiple measures on network composition for all our personal networks at once.

3. **Structural analysis**. We'll write an R function that calculates multiple structural measures on a personal network and we'll run it on all the personal networks in our data at once. 

4. **Association with ego-level variables**. We'll merge the results of personal network compositional and structural analysis with non-network ego-level data, and we'll analyze the association between ego-level attributes and personal network characteristics.

```{r case-study, include=TRUE, cache=FALSE, tidy= FALSE, out.width = "70%"}
```

<!--chapter:end:07_Supplementary.Rmd-->

`r if (knitr::is_html_output()) '
# References {-}
'`

<!--chapter:end:08_References.Rmd-->

